{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c630b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, time,json\n",
    "import tmdbsimple as tmdb \n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import tmdbsimple as tmdb\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a72f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the api login info\n",
    "with open('/Users/alicechen/.secret/tmdb_api.json') as f:\n",
    "    login = json.load(f)\n",
    "login.keys()\n",
    "tmdb.API_KEY = login['API Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc51438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    #Get the movies object for current id \n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    #Loop through countries in releases\n",
    "    for c in  releases['countries']:\n",
    "        if c['iso_3166_1'] == 'US':\n",
    "        # if the country == US\n",
    "        ## GET \"certification\" Key\n",
    "            info[\"certification\"]= c[\"certification\"]\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23ea70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_tmdb_data_2018.csv.gz',\n",
       " 'final_tmdb_data_2014.csv.gz',\n",
       " 'final_tmdb_data_2016.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2012.csv.gz',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_rating.csv.gz',\n",
       " 'final_tmdb_data_2019.csv.gz',\n",
       " 'final_tmdb_data_2015.csv.gz',\n",
       " 'final_tmdb_data_2017.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " '.ipynb_checkpoints',\n",
       " 'final_tmdb_data_2013.csv.gz',\n",
       " 'title_akas.csv.gz',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = 'Data/'\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8c18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cefed98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET = [2020,2021]\n",
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30f520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El Tango del Viudo y Su Espejo Deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0096056</td>\n",
       "      <td>movie</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>Crime and Punishment</td>\n",
       "      <td>0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType                                       primaryTitle  \\\n",
       "0  tt0035423     movie                                     Kate & Leopold   \n",
       "1  tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
       "2  tt0069049     movie                         The Other Side of the Wind   \n",
       "3  tt0088751     movie                                  The Naked Monster   \n",
       "4  tt0096056     movie                               Crime and Punishment   \n",
       "\n",
       "                               originalTitle  isAdult  startYear  endYear  \\\n",
       "0                             Kate & Leopold        0     2001.0      NaN   \n",
       "1  El Tango del Viudo y Su Espejo Deformante        0     2020.0      NaN   \n",
       "2                 The Other Side of the Wind        0     2018.0      NaN   \n",
       "3                          The Naked Monster        0     2005.0      NaN   \n",
       "4                       Crime and Punishment        0     2002.0      NaN   \n",
       "\n",
       "   runtimeMinutes                  genres  \n",
       "0             118  Comedy,Fantasy,Romance  \n",
       "1              70                   Drama  \n",
       "2             122                   Drama  \n",
       "3             100    Comedy,Horror,Sci-Fi  \n",
       "4             126                   Drama  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open saved file and preview again\n",
    "basics = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory = False)\n",
    "basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580a64be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014539003372192383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "YEARS",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7122e0d68a746cd91a477fe5ce04740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011849164962768555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Movies from 2020",
       "rate": null,
       "total": 5215,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8699c95a31694d3dbcfd4b173da8852a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2020:   0%|          | 0/5215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011345863342285156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Movies from 2021",
       "rate": null,
       "total": 5309,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0745734ce70f4d9fa38455897037dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2021:   0%|          | 0/5309 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start of the OUTER LOOP\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc= 'YEARS', position = 0):\n",
    "\n",
    "    # define the JSON file to store results\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "    # check if the file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "    # if the file doesn't exist, create it\n",
    "    if file_exists == False:\n",
    "        with open(JSON_FILE, 'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "    # save new year as the current df\n",
    "    df = basics.loc[basics['startYear']==YEAR].copy()\n",
    "\n",
    "    # save movie ids to list\n",
    "    movie_ids = df['tconst'].copy() #to_list()\n",
    "    movie_ids\n",
    "\n",
    "    # load existing data fro json into new file\n",
    "    previous_df = pd.read_json(JSON_FILE)\n",
    "    previous_df\n",
    "\n",
    "    # filter out any ids that are already in the JSON_FILE\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                 desc=f'Movies from {YEAR}',\n",
    "                                 position = 1,\n",
    "                                 leave = True):\n",
    "        try:\n",
    "            temp = get_movie_with_rating(movie_id)\n",
    "            write_json(temp,JSON_FILE)\n",
    "            time.sleep(0.02)\n",
    "        except Exception as e: \n",
    "            errors.append([movie_id, e])\n",
    "            \n",
    "\n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44ac6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 2347\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7a24f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/final_tmdb_data_2018.csv.gz',\n",
       " 'Data/final_tmdb_data_2014.csv.gz',\n",
       " 'Data/final_tmdb_data_2016.csv.gz',\n",
       " 'Data/final_tmdb_data_2020.csv.gz',\n",
       " 'Data/final_tmdb_data_2000.csv.gz',\n",
       " 'Data/final_tmdb_data_2012.csv.gz',\n",
       " 'Data/final_tmdb_data_2019.csv.gz',\n",
       " 'Data/final_tmdb_data_2015.csv.gz',\n",
       " 'Data/final_tmdb_data_2021.csv.gz',\n",
       " 'Data/final_tmdb_data_2017.csv.gz',\n",
       " 'Data/final_tmdb_data_2001.csv.gz',\n",
       " 'Data/final_tmdb_data_2013.csv.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use glob to append data\n",
    "q = \"Data/final_tmdb_data_*.csv.gz\"\n",
    "chunked_files = glob.glob(q)\n",
    "chunked_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6051d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/final_tmdb_data_2018.csv.gz\n",
      "Data/final_tmdb_data_2014.csv.gz\n",
      "Data/final_tmdb_data_2016.csv.gz\n",
      "Data/final_tmdb_data_2020.csv.gz\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m chunked_files:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m----> 5\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimdb_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrevenue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbudget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcertification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(temp_df)\n\u001b[1;32m      7\u001b[0m     tmdb_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df_list)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "## Loading all files as df and appending to a list\n",
    "df_list = []\n",
    "for file in chunked_files:\n",
    "    print(file)\n",
    "    temp_df = pd.read_csv(file,usecols=['imdb_id','revenue','budget','certification'])\n",
    "    df_list.append(temp_df)\n",
    "    tmdb_data = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "413aab6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>certification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0192528</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0360556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0365545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0427543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>tt9387300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>tt9434008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>tt9547878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>tt9741588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>tt9753312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12159 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        imdb_id      budget  revenue certification\n",
       "1     tt0069049  12000000.0      0.0             R\n",
       "2     tt0192528   5000000.0      0.0           NaN\n",
       "3     tt0360556         0.0      0.0         PG-13\n",
       "4     tt0365545         0.0      0.0           NaN\n",
       "5     tt0427543         0.0      0.0           NaN\n",
       "...         ...         ...      ...           ...\n",
       "3954  tt9387300         0.0      0.0           NaN\n",
       "3955  tt9434008         0.0      0.0           NaN\n",
       "3956  tt9547878         0.0      0.0           NaN\n",
       "3957  tt9741588         0.0      0.0           NaN\n",
       "3958  tt9753312         0.0      0.0           NaN\n",
       "\n",
       "[12159 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "339bafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_data = tmdb_data[tmdb_data.imdb_id != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38a15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
